# pt-cloudengine-worker-comfyui-basic

Custom RunPod worker for [ComfyUI](https://github.com/comfyanonymous/ComfyUI)  
Maintained by [Pseudotools](https://github.com/pseudotools)

## Overview
This worker provides a baseline ComfyUI runtime with:
- Core SDXL models baked into the image
- Automatically cloned [Pseudotools "Pseudocomfy" Custom Nodes](https://github.com/Pseudotools/Pseudocomfy)
- Configurable persistent storage at `/runpod-volume/models` for additional models

## References
- [RunPod Worker Documentation](https://docs.runpod.io/serverless/workers/)
- [RunPod ComfyUI Worker Repo](https://github.com/runpod-workers/worker-comfyui)
- [GitHub Integration Setup](https://docs.runpod.io/serverless/workers/github-integration)
- [Hugging Face Model Repo](https://huggingface.co/pseudotools/pseudocomfy-models)



## üöÄ Deployment on RunPod

This repository defines a **custom RunPod Serverless Worker** for [ComfyUI](https://github.com/comfyanonymous/ComfyUI), configured with Pseudotools‚Äô core models and custom nodes.
The worker runs entirely within RunPod‚Äôs serverless infrastructure and communicates through the RunPod API ‚Äî no exposed ports or manual networking required.

---

### üß© 1. Prerequisites

* A [RunPod account](https://www.runpod.io/console) with access to **Serverless ‚Üí Workers**.
* A linked [GitHub account](https://docs.runpod.io/serverless/workers/github-integration).
* A [Hugging Face account](https://huggingface.co/pseudotools/pseudocomfy-models) (optional for browsing models, not required for access).

---

### ‚öôÔ∏è 2. Connect the GitHub Repository

1. In the RunPod Console, go to **Serverless ‚Üí Workers ‚Üí Create Worker**.
2. Choose **‚ÄúFrom GitHub Repository.‚Äù**
3. Select:

   * **Repository:** `pseudotools/pt-cloudengine-worker-basic`
   * **Branch:** `main`
   * **Dockerfile path:** `/Dockerfile` (default)
4. Leave **Container Start Command** blank ‚Äî the base image defines the correct entrypoint.
5. Leave **Model (optional)** blank ‚Äî models are downloaded automatically inside the image.
6. Do **not** expose any ports. This worker communicates through the RunPod job API.

üìò Reference: [RunPod GitHub Integration Guide](https://docs.runpod.io/serverless/workers/github-integration)

---

### üîê 3. Configure Environment Variables

Under **Environment Variables**, add the following:

| Variable             | Example                    | Purpose                                      | Secret? |
| -------------------- | -------------------------- | -------------------------------------------- | ------- |
| `COMFYUI_AUTH_TOKEN` | `pseudotools-secret-token` | Used by clients to authenticate API requests | ‚úÖ       |
| `MODEL_PATH`         | `/app/models`              | Directory containing baked-in models         | ‚ùå       |
| `CUSTOM_NODE_PATH`   | `/app/custom_nodes`        | Directory containing custom node definitions | ‚ùå       |
| `LOG_LEVEL`          | `info`                     | Logging verbosity for worker                 | ‚ùå       |

üí° **Important:**
Secrets like `COMFYUI_AUTH_TOKEN` are stored securely in RunPod and injected at runtime.
They should never be included in GitHub or your Dockerfile.

üìò Reference: [RunPod Environment Variables](https://docs.runpod.io/serverless/workers/environment-variables)

---

### üß± 4. Build and Deploy

Click **Deploy Worker**.
RunPod will automatically:

1. Clone this repository.
2. Build the Docker image using the provided Dockerfile.
3. Download core models from [Hugging Face](https://huggingface.co/pseudotools/pseudocomfy-models).
4. Clone and install [Pseudocomfy custom nodes](https://github.com/Pseudotools/Pseudocomfy).
5. Register the worker with the RunPod job system.

Build time typically takes 20‚Äì30 minutes (depending on model size).
You can monitor progress in **Build Logs**.

‚úÖ **Build succeeds when:**

* Model downloads complete without errors.
* Custom nodes install successfully.
* The worker logs show it‚Äôs ‚Äúready‚Äù or listening for RunPod jobs.

---

### üß™ 5. Test the Worker Endpoint

Once deployment completes:

1. In **RunPod ‚Üí Workers**, open your worker and click **Endpoints ‚Üí View Worker Endpoint**.
   You‚Äôll get a public endpoint like:

   ```
   https://api.runpod.ai/v2/<worker-id>/run
   ```

2. Send a test request:

   ```bash
   curl -X POST https://api.runpod.ai/v2/<worker-id>/run \
     -H "Authorization: Bearer <COMFYUI_AUTH_TOKEN>" \
     -H "Content-Type: application/json" \
     -d '{"input": {"prompt": "an architectural scene with natural light"}}'
   ```

3. The worker will respond with job metadata and begin processing.
   Jobs can be monitored via the RunPod dashboard or API.

üìò Reference: [RunPod API Reference](https://docs.runpod.io/reference)

---

### üß† 6. Model and Node Directories

The following directories are used inside the container:

| Variable           | Path                | Purpose                                                                                                                        |
| ------------------ | ------------------- | ------------------------------------------------------------------------------------------------------------------------------ |
| `MODEL_PATH`       | `/app/models`       | Contains baked-in models from the [Pseudotools Hugging Face repository](https://huggingface.co/pseudotools/pseudocomfy-models) |
| `CUSTOM_NODE_PATH` | `/app/custom_nodes` | Contains Pseudotools custom node definitions cloned from GitHub                                                                |

These environment variables tell ComfyUI where to look for models and custom nodes;
they don‚Äôt define which models exist.

Optionally, you can mount a persistent volume at `/runpod-volume/models`
to add or update models without rebuilding the image.

---

### üì¶ 7. Verify the Deployment

After the worker starts, open the **Logs** tab in RunPod and confirm:

```
‚úÖ Downloaded model sd_xl_base_1.0.safetensors
‚úÖ Cloned custom nodes from Pseudotools/Pseudocomfy
üß† MODEL_PATH=/app/models
üß© CUSTOM_NODE_PATH=/app/custom_nodes
Worker initialized and listening for jobs...
```

---

### üß≠ 8. Integration with Pseudotools Cloud Engine

Once verified, register the new worker endpoint in your orchestration service
(`pt-cloudengine-dispatcher` or equivalent) by adding it as a ComfyUI backend:

```python
headers = {
    "Authorization": f"Bearer {COMFYUI_AUTH_TOKEN}",
    "Content-Type": "application/json"
}

requests.post(
    "https://api.runpod.ai/v2/<worker-id>/run",
    headers=headers,
    json={"input": {"workflow": "Hugo", "prompt": "sunlit atrium"}}
)
```

This allows your local or cloud services to dispatch jobs directly to this worker.

---

### ‚úÖ 9. Notes and Best Practices

* **Build limits:** RunPod GitHub builds must complete within 160 minutes and stay under 80 GB total image size.
* **Security:** Never bake secrets or tokens into the Dockerfile.
* **Variants:**
  Fork this repo for additional worker types:

  * `pt-cloudengine-worker-comfyui-xl` ‚Äî extended SDXL setup
  * `pt-cloudengine-worker-comfyui-lora` ‚Äî LoRA or ControlNet-heavy builds
  * `pt-cloudengine-worker-comfyui-materials` ‚Äî material inference builds
* **Persistence:**
  Mount `/runpod-volume/models` or `/runpod-volume/custom_nodes` to retain files between runs.

---

### üìö References

* [RunPod Serverless Workers](https://docs.runpod.io/serverless/workers/)
* [RunPod GitHub Integration](https://docs.runpod.io/serverless/workers/github-integration)
* [RunPod API Reference](https://docs.runpod.io/reference)
* [ComfyUI Repository](https://github.com/comfyanonymous/ComfyUI)
* [Pseudotools Custom Nodes](https://github.com/Pseudotools/Pseudocomfy)
* [Pseudotools Model Repository](https://huggingface.co/pseudotools/pseudocomfy-models)

